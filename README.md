# CNN-based Super-Resolution for Ocean Current Data

This project demonstrates how to use a basic Convolutional Neural Network (CNN) for Super-Resolution (SR) reconstruction of ocean current data (e.g., `u_bar` and `v_bar`). The project includes a complete end-to-end example, a practice template for hands-on experience, and data processing scripts.

## âœ¨ Features

- **End-to-End Workflow**: Provides a complete workflow from data loading, model training, and validation to testing and visualization in a Jupyter Notebook (`Task1_CNN_SuperResolution_example.ipynb`).
- **Basic CNN Model**: Implements a simple yet effective CNN model tailored for the super-resolution task.
- **Result Visualization**: Generates comparison plots to visually showcase the differences between Low-Resolution input (LQ), High-Resolution ground truth (GT), and the model's Super-Resolution output (SR).
- **Model & Prediction Saving**: Automatically saves the best-performing model based on the validation set and can save partial predictions as `.npy` files for further analysis.
- **Hands-on Practice**: Includes a practice notebook (`Task1_CNN_SuperResolution_practice.ipynb`) to encourage users to replicate the entire process on the `v_bar` dataset.
- **Data Utility**: Contains a helper script (`data_demo.py`) to create smaller data subsets from the full dataset, facilitating quick debugging and experiments.

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ u_bar/              # U-component ocean current data
â”‚   â”‚   â”œâ”€â”€ ubar_hr_train.npy
â”‚   â”‚   â”œâ”€â”€ ubar_sr_input_train.npy
â”‚   â”‚   â””â”€â”€ ... (val, test datasets)
â”‚   â””â”€â”€ v_bar/              # V-component ocean current data
â”‚       â”œâ”€â”€ vbar_hr_train.npy
â”‚       â””â”€â”€ ... (val, test datasets)
â”œâ”€â”€ sr_cnn_results_ubar_demo/ # Output directory for the example code
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â”œâ”€â”€ test_visualization.png
â”‚   â””â”€â”€ validation_npy_predictions/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ data_demo.py            # Script for creating a small-scale demo dataset
â”œâ”€â”€ Task1_CNN_SuperResolution_example.ipynb # Core example: Complete SR workflow using u_bar data
â”œâ”€â”€ Task1_CNN_SuperResolution_practice.ipynb # Practice task: Replicate the SR workflow on v_bar data
â””â”€â”€ README.md               # This document
```

## âš™ï¸ Requirements

Please ensure you have the following Python libraries installed. You can install them using pip:

```sh
pip install torch numpy matplotlib
```

## ğŸš€ Usage Guide

### 1. Run the Core Example

Open and run `Task1_CNN_SuperResolution_example.ipynb` directly in a Jupyter environment.

- This notebook will use the data from the `data/u_bar` directory.
- It will perform model training, validation, and testing.
- All outputs (best model, visualization images, predicted .npy files) will be saved in the `sr_cnn_results_ubar_demo/` directory.

### 2. Complete the Practice Task

Open `Task1_CNN_SuperResolution_practice.ipynb` and, following the prompts and referencing the example code, complete the code to build a new super-resolution task for the `v_bar` dataset.

### 3. Create a Demo Dataset (Optional)

If you want to use a smaller dataset for quick testing, you can run `data_demo.py`.

1.  Open the `data_demo.py` file.
2.  Modify the `DEMO_SAMPLE_COUNT` variable to define the number of samples for each dataset.
3.  Modify the file paths in `file_processing_list` to ensure they point to your original data and desired output locations.
4.  Run the script from your terminal:
    ```sh
    python data_demo.py
    ```

## ğŸ“Š Output

After running `Task1_CNN_SuperResolution_example.ipynb`, the following will be generated in the `sr_cnn_results_ubar_demo/` directory:

- `best_model.pth`: The model weights file with the lowest loss on the validation set.
- `test_visualization.png`: A comparison plot with 5 subplots showing LQ, GT, SR, and the errors between them.
- `validation_npy_predictions/`: A subdirectory containing several `.npy` files, which save the LQ, GT, and SR data for some validation samples.

## Getting Started

1.  **Clone/Download the Project**: Get a local copy of this project.
2.  **Prepare the Data**: Ensure the `data/` directory contains the `u_bar` and `v_bar` data. If the data is missing, you may need to run a data preparation script or place it manually.
3.  **Install Dependencies**: `pip install torch numpy matplotlib`.
4.  **Run the Example**: Open and run `Task1_CNN_SuperResolution_example.ipynb` from start to finish to understand the entire workflow and see the results.
5.  **Hands-on Practice**: Try to complete the exercises in `Task1_CNN_SuperResolution_practice.ipynb` to solidify your understanding.

## ğŸ“ Notes

- **Device Configuration**: The code will automatically detect and prioritize using a CUDA-enabled GPU. If no GPU is available, it will fall back to CPU execution. Training on a CPU can be very time-consuming.
- **Path Configuration**: All paths in the notebooks and scripts are relative. Please ensure you run them from the project's root directory, or you may need to adjust the file paths.
- **Data Format**: This project uses the `.npy` file format for data storage. The data is assumed to be a 3D array of shape `(num_samples, height, width)`, where `height` and `width` are the dimensions of the ocean current data fields.
