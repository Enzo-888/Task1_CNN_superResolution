{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229672da",
   "metadata": {},
   "source": [
    "## 这是一个练习模板，其中包含了 `example` 的大部分代码，但需要您动手修改和补充，以完成对 `v_bar` 数据的超分辨率任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550514b",
   "metadata": {},
   "source": [
    "## 超参数与配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # --- 数据与保存路径 ---\n",
    "    # 数据集所在的根目录\n",
    "    DATA_DIR = \"data/v_bar\"  \n",
    "    # 模型和可视化结果的保存目录\n",
    "    SAVE_DIR = \"./sr_cnn_results_vbar_demo\"\n",
    "\n",
    "    # --- 文件名模板 ---\n",
    "    LQ_TEMPLATE = \"ubar_sr_input_{split}.npy\"\n",
    "    GT_TEMPLATE = \"ubar_hr_{split}.npy\"\n",
    "    META_FILES = {\n",
    "        \"mask\": \"mask.npy\",\n",
    "        \"lat\": \"lat.npy\",\n",
    "        \"lon\": \"lon.npy\"\n",
    "    }\n",
    "    \n",
    "    # --- 训练参数 ---\n",
    "    BATCH_SIZE = 16\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_EPOCHS = 1  #自行调整\n",
    "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    IN_CHANNELS = 1   \n",
    "    OUT_CHANNELS = 1\n",
    "    HIDDEN_DIMS = 64\n",
    "\n",
    "# 创建保存目录，如果不存在\n",
    "os.makedirs(Config.SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e2f35",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd91ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    为海洋超分任务定制的PyTorch Dataset。\n",
    "    直接加载预先分割好的 low-resolution (lq) 和 high-resolution (gt) 数据。\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, lq_filename, gt_filename):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): 数据文件所在的目录。\n",
    "            lq_filename (str): 低分辨率数据的文件名。\n",
    "            gt_filename (str): 高分辨率数据的文件名。\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lq_path = os.path.join(data_dir, lq_filename)\n",
    "            gt_path = os.path.join(data_dir, gt_filename)\n",
    "            \n",
    "            # 加载数据并转换为 float32\n",
    "            self.lq_data = np.load(lq_path).astype(np.float32)\n",
    "            self.gt_data = np.load(gt_path).astype(np.float32)\n",
    "\n",
    "            print(f\"成功加载数据: {lq_filename} (shape: {self.lq_data.shape}) 和 {gt_filename} (shape: {self.gt_data.shape})\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            raise FileNotFoundError(f\"错误: 数据文件未找到。请确保路径 '{data_dir}' 正确且包含所需文件。\\n{e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.lq_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 从 (H, W) 扩展为 (C, H, W) 以符合CNN输入要求\n",
    "        lq_sample = torch.from_numpy(self.lq_data[idx]).unsqueeze(0)\n",
    "        gt_sample = torch.from_numpy(self.gt_data[idx]).unsqueeze(0)\n",
    "        \n",
    "        return {'lq': lq_sample, 'gt': gt_sample}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b155b",
   "metadata": {},
   "source": [
    "## CNN 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSRCNN(nn.Module):\n",
    "    \"\"\"一个用于超分辨率的基础CNN模型\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, hidden_dim):\n",
    "        super(SimpleSRCNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入的低分辨率图像, shape (B, C_in, H, W)\n",
    "        Returns:\n",
    "            torch.Tensor: 输出的超分辨率图像, shape (B, C_out, H, W)\n",
    "        \"\"\"\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf733cff",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_l2_error(pred, gt, mask):\n",
    "    \"\"\"\n",
    "    计算在有效区域（mask内）的相对L2误差。\n",
    "    公式: ||pred - gt||_2 / ||gt||_2\n",
    "    \n",
    "    Args:\n",
    "        pred (torch.Tensor): 模型的预测结果。\n",
    "        gt (torch.Tensor): 真实的高分辨率数据。\n",
    "        mask (torch.Tensor): 布尔掩码，True表示有效计算区域。\n",
    "        \n",
    "    Returns:\n",
    "        float: 计算出的相对L2误差。\n",
    "    \"\"\"\n",
    "    # 确保只在有效区域计算\n",
    "    pred_masked = pred[mask]\n",
    "    gt_masked = gt[mask]\n",
    "    \n",
    "    error_norm = torch.linalg.norm(pred_masked - gt_masked)\n",
    "    gt_norm = torch.linalg.norm(gt_masked)\n",
    "    \n",
    "    # 防止除以零\n",
    "    if gt_norm == 0:\n",
    "        return float('inf') if error_norm > 0 else 0.0\n",
    "        \n",
    "    return (error_norm / gt_norm).item()\n",
    "\n",
    "def plot_results(lq, gt, sr, mask, lon, lat, save_path):\n",
    "    \"\"\"\n",
    "    严谨地可视化lq, gt, sr以及它们与gt之间的误差。\n",
    "    \n",
    "    -  颜色方案与示例对齐 (RdBu_r)，前三张图共享色标。\n",
    "    -  图像设置为正方形长宽比。\n",
    "    -  除了保存文件，也会显示图像。\n",
    "    - 五张子图，每张图都有独立的colorbar。\n",
    "    - 使用经纬度作为坐标轴。\n",
    "    - 应用mask，将无效区域（陆地）显示为灰色。\n",
    "    \"\"\"\n",
    "    lq = np.squeeze(lq) # 形状变为 (H, W)\n",
    "    gt = np.squeeze(gt)\n",
    "    sr = np.squeeze(sr)\n",
    "\n",
    "    # 将mask外的区域设置为NaN以便于绘图忽略\n",
    "    lq[~mask] = np.nan\n",
    "    gt[~mask] = np.nan\n",
    "    sr[~mask] = np.nan\n",
    "\n",
    "    error_sr = sr - gt\n",
    "    error_lq = lq - gt\n",
    "    error_sr[~mask] = np.nan\n",
    "    error_lq[~mask] = np.nan\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(35, 8), dpi=150)\n",
    "    \n",
    "    titles = [\n",
    "        'Low-Resolution Input (LQ)', 'High-Resolution Ground Truth (GT)', 'Super-Resolution Output (SR)',\n",
    "        'Error (SR - GT)', 'Error (LQ - GT)'\n",
    "    ]\n",
    "    data_maps = [lq, gt, sr, error_sr, error_lq]\n",
    "    \n",
    "    data_vmin = np.nanmin((lq, gt, sr))\n",
    "    data_vmax = np.nanmax((lq, gt, sr))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        data = data_maps[i]\n",
    "        cmap = 'RdBu_r'\n",
    "        \n",
    "        # 为数据图和误差图设定不同的颜色范围逻辑\n",
    "        if 'Error' in titles[i]:\n",
    "            # 误差图：色条应以0为中心对称\n",
    "            vmax_abs = np.nanmax(np.abs(data))\n",
    "            vmin, vmax = -vmax_abs, vmax_abs\n",
    "        else:\n",
    "            # 数据图：使用统一的颜色范围\n",
    "            vmin, vmax = data_vmin, data_vmax\n",
    "            \n",
    "        # 使用 pcolormesh 以正确处理经纬度坐标\n",
    "        im = ax.pcolormesh(lon, lat, data, cmap=cmap, vmin=vmin, vmax=vmax, shading='auto')\n",
    "        \n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "        \n",
    "        ax.set_title(titles[i], fontsize=16, pad=12)\n",
    "        ax.set_xlabel('Longitude', fontsize=14)\n",
    "        ax.set_ylabel('Latitude', fontsize=14)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        \n",
    "        # 设置背景色为灰色，代表陆地\n",
    "        ax.set_facecolor('0.75')\n",
    "        \n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.tight_layout(pad=2.5)\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"可视化结果已保存至: {save_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "def save_predictions_as_npy(model, loader, mask, save_dir, num_samples=3):\n",
    "    \"\"\"\n",
    "    使用模型对验证集中的样本进行预测，并将指定数量的结果保存为.npy文件。同时保存对应的lq和gt文件\n",
    "    陆地区域的值将被设置为 NaN。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 正在保存 {num_samples} 个验证集预测结果为 .npy 文件 ---\")\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建一个子目录来存放 .npy 文件\n",
    "    output_dir = os.path.join(save_dir, \"validation_npy_predictions\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    saved_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if saved_count >= num_samples:\n",
    "                break\n",
    "                \n",
    "            lq_tensor = batch['lq'].to(Config.DEVICE)\n",
    "            gt_tensor = batch['gt'].to(Config.DEVICE) # gt也需要用来保存\n",
    "            sr_tensor = model(lq_tensor)\n",
    "            \n",
    "            # 在一个批次中处理每个样本，直到保存够数量\n",
    "            for i in range(sr_tensor.shape[0]):\n",
    "                if saved_count >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                # 获取单个样本，移至CPU并转换为numpy\n",
    "                lq_np = lq_tensor[i].squeeze().cpu().numpy()\n",
    "                gt_np = gt_tensor[i].squeeze().cpu().numpy()\n",
    "                sr_np = sr_tensor[i].squeeze().cpu().numpy()\n",
    "                \n",
    "                # 应用mask，将陆地区域设置为 NaN\n",
    "                lq_np[~mask] = np.nan\n",
    "                gt_np[~mask] = np.nan\n",
    "                sr_np[~mask] = np.nan\n",
    "                \n",
    "                # 创建文件名（使用虚拟日期）\n",
    "                date_str = f\"2018-01-{saved_count + 1:02d}\"\n",
    "                \n",
    "                save_path_lq = os.path.join(output_dir, f\"{date_str}_lq.npy\")\n",
    "                save_path_gt = os.path.join(output_dir, f\"{date_str}_gt.npy\")\n",
    "                save_path_sr = os.path.join(output_dir, f\"{date_str}_sr.npy\")\n",
    "                \n",
    "                np.save(save_path_lq, lq_np)\n",
    "                np.save(save_path_gt, gt_np)\n",
    "                np.save(save_path_sr, sr_np)\n",
    "                # 保存文件\n",
    "                print(f\"  已保存 {date_str} 对应的 lq, gt, sr 文件。\")\n",
    "                \n",
    "                saved_count += 1\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3988040",
   "metadata": {},
   "source": [
    "## 训练验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ac801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, mask_tensor, device):\n",
    "    model.train()\n",
    "    pass\n",
    "\n",
    "def validate(model, loader, criterion, mask_tensor, device):\n",
    "    model.eval()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a125f",
   "metadata": {},
   "source": [
    "## 执行流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"主函数，执行完整的训练、评估和可视化流程。\"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FNO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
